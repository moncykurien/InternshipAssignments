{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementNotInteractableException, ElementClickInterceptedException\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import requests\n",
    "import urllib.parse\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a common launch pad for chrome browser with Webdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drive_launch(url):\n",
    "    \"\"\"\n",
    "    This function initiates the Chrome browser's driver with the url passed as a parameter and returns the driver instance.\n",
    "    Parameters:\n",
    "        url - url of the website\n",
    "    return:\n",
    "        driver - driver instance of the chrome browser    \n",
    "    \"\"\"\n",
    "    #creating driver instance\n",
    "    driver = webdriver.Chrome('./driver/chromedriver.exe')\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    #defining implicit wait\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    #launching the url\n",
    "    driver.get(url)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a python program which searches all the product under a particular product from www.amazon.in. The product name to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_product_amazon(product):\n",
    "    product = product.lower()\n",
    "    url = 'https://www.amazon.in/'\n",
    "    \n",
    "    drivr = get_drive_launch(url)\n",
    "    drivr.find_element_by_id(\"twotabsearchtextbox\").send_keys(product)\n",
    "    drivr.find_element_by_xpath(\"//input[@type='submit' and @value='Go']\").click()\n",
    "    search_text = drivr.find_element_by_xpath(\"//div[@class='a-section a-spacing-small a-spacing-top-small']\").text\n",
    "    print(\"Showing\",search_text)\n",
    "    return drivr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 1-48 of over 1,000 results for \"guitar\"\n"
     ]
    }
   ],
   "source": [
    "product = 'guitar'\n",
    "d = search_product_amazon(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a dataframe and csv. In case if any product vertical has less than 3 pages in search results then scrape all the products available under that product vertical. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_product_details_amazon(product, pages, save_as_csv = False):\n",
    "    d = search_product_amazon(product)\n",
    "    num_pages = pages\n",
    "    page_num = 1\n",
    "    time.sleep(2)\n",
    "    brands = []\n",
    "    product_names = []\n",
    "    ratings = []\n",
    "    num_ratings = []\n",
    "    prices = []\n",
    "    expected_delivery = []\n",
    "    availabilities = []\n",
    "    prod_urls = []\n",
    "    other_details = []\n",
    "    returns = []\n",
    "\n",
    "    next_tab = True\n",
    "\n",
    "    while (page_num < num_pages + 1):\n",
    "        time.sleep(2)\n",
    "        page_num += 1\n",
    "        main_window = d.current_window_handle\n",
    "\n",
    "        plp_product_elems = d.find_elements_by_xpath(\"//div[@data-component-type='s-search-result']\")\n",
    "        \n",
    "        for prod_elems in range(len(plp_product_elems)):\n",
    "            try:\n",
    "                try:\n",
    "                    plp_product_elems[prod_elems].click()\n",
    "                except:\n",
    "                    continue\n",
    "            except StaleElementReferenceException:\n",
    "                try:\n",
    "                    d.get(d.current_url)\n",
    "                    time.sleep(2)\n",
    "                    plp_product_elems = d.find_elements_by_xpath(\"//div[@data-component-type='s-search-result']\")\n",
    "                    #d.navigate().refresh()\n",
    "                    time.sleep(2)\n",
    "                    plp_product_elems[prod_elems].click()\n",
    "                except:\n",
    "                    continue\n",
    "            except ElementNotInteractableException:\n",
    "                d.find_element_by_xpath(\"//a[@class='a-link-normal a-carousel-goto-nextpage s-carousel-button']\").click()\n",
    "                time.sleep(1)\n",
    "                prod_elems.click()\n",
    "\n",
    "            all_windows = d.window_handles\n",
    "\n",
    "            if len(all_windows) > 1:\n",
    "                try:\n",
    "                    d.switch_to.window(all_windows[1])\n",
    "                except NoSuchWindowException:\n",
    "                    continue\n",
    "                next_tab = True\n",
    "            else:\n",
    "                next_tab = False\n",
    "\n",
    "            try:\n",
    "                try:\n",
    "                    try:\n",
    "                        brands.append(d.find_element_by_id(\"bylineInfo\").text)\n",
    "                    except:\n",
    "                        brands.append(\"-\")\n",
    "                except NoSuchElementException:\n",
    "                    brands.append(\"-\") \n",
    "                try:\n",
    "                    product_names.append(d.find_element_by_id(\"productTitle\").text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    product_names.append(\"-\")\n",
    "                try:\n",
    "                    rating = d.find_element_by_xpath(\"//div[@id='averageCustomerReviews_feature_div']//span[@class='a-icon-alt']\").text.strip()\n",
    "                    ratings.append(rating)\n",
    "                    num_ratings.append(d.find_element_by_xpath(\"//div[@id='averageCustomerReviews_feature_div']//span[@id='acrCustomerReviewText']\").text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    ratings.append(\"-\")\n",
    "                    num_ratings.append(\"-\")\n",
    "                try:\n",
    "                    prices.append(d.find_element_by_id(\"priceblock_ourprice\").text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    try:\n",
    "                        prices.append(d.find_element_by_id(\"priceblock_dealprice\").text.strip())\n",
    "                    except NoSuchElementException:\n",
    "                        try:\n",
    "                            prices.append(d.find_element_by_id(\"priceblock_saleprice\").text.strip())\n",
    "                        except NoSuchElementException:\n",
    "                            prices.append(\"-\")\n",
    "                try:\n",
    "                    expected_delivery.append(d.find_element_by_id(\"ddmDeliveryMessage\").text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    expected_delivery.append(\"-\")\n",
    "                try:\n",
    "                    avl = d.find_element_by_id(\"availability\").text.strip()\n",
    "                    if len(avl) > 0:\n",
    "                        availabilities.append(avl)\n",
    "                    else:\n",
    "                        availabilities.append(\"-\")\n",
    "                except NoSuchElementException:\n",
    "                    availabilities.append(\"-\")\n",
    "                prod_urls.append(d.current_url)\n",
    "                try:\n",
    "                    other_details.append(d.find_element_by_id('feature-bullets').text)\n",
    "                except NoSuchElementException:\n",
    "                    other_details.append(\"-\")\n",
    "                try:\n",
    "                    returns.append(d.find_element_by_xpath(\"//div[@id='RETURNS_POLICY']//a\").text)\n",
    "                except NoSuchElementException:\n",
    "                    returns.append(\"-\")\n",
    "            except StaleElementReferenceException:\n",
    "                d.navigate().refresh()\n",
    "                time.sleep(2)\n",
    "                try:\n",
    "                    brands.append(d.find_element_by_id(\"bylineInfo\").text)\n",
    "                except NoSuchElementException:\n",
    "                    brands.append(\"-\")\n",
    "                try:\n",
    "                    product_names.append(d.find_element_by_id(\"productTitle\").text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    product_names.append(\"-\")\n",
    "                try:\n",
    "                    rating = d.find_element_by_xpath(\"//div[@id='averageCustomerReviews_feature_div']//span[@class='a-icon-alt']\").text.strip()\n",
    "                    ratings.append(rating)\n",
    "                    num_ratings.append(d.find_element_by_xpath(\"//div[@id='averageCustomerReviews_feature_div']//span[@id='acrCustomerReviewText']\").text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    ratings.append(\"-\")\n",
    "                    num_ratings.append(\"-\")            \n",
    "                try:\n",
    "                    prices.append(d.find_element_by_id(\"priceblock_ourprice\").text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    try:\n",
    "                        prices.append(d.find_element_by_id(\"priceblock_dealprice\").text.strip())\n",
    "                    except NoSuchElementException:\n",
    "                        try:\n",
    "                            prices.append(d.find_element_by_id(\"priceblock_saleprice\").text.strip())\n",
    "                        except NoSuchElementException:\n",
    "                            prices.append(\"-\")\n",
    "                try:\n",
    "                    expected_delivery.append(d.find_element_by_id(\"ddmDeliveryMessage\").text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    expected_delivery.append(\"-\")\n",
    "                try:\n",
    "                    avl = d.find_element_by_id(\"availability\").text.strip()\n",
    "                    if len(avl) > 0:\n",
    "                        availabilities.append(avl)\n",
    "                    else:\n",
    "                        availabilities.append(\"-\")\n",
    "                except NoSuchElementException:\n",
    "                    availabilities.append(\"-\")\n",
    "                prod_urls.append(d.current_url)\n",
    "                try:\n",
    "                    other_details.append(d.find_element_by_id('feature-bullets').text)\n",
    "                except NoSuchElementException:\n",
    "                    other_details.append(\"-\")\n",
    "                try:\n",
    "                    returns.append(d.find_element_by_xpath(\"//div[@id='RETURNS_POLICY']//a\").text)\n",
    "                except NoSuchElementException:\n",
    "                    returns.append(\"-\")\n",
    "\n",
    "            if next_tab:\n",
    "                d.close()\n",
    "                d.switch_to.window(main_window)\n",
    "            else:\n",
    "                d.back()\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            next_page_url = d.find_element_by_xpath(\"//li[@class='a-last']//a\").get_attribute('href')\n",
    "            d.quit()\n",
    "            d = get_drive_launch(next_page_url)\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "    df = pd.DataFrame({'Brand Name':brands, \"Name of the Product\": product_names, \"Rating\":ratings, \"No. of Ratings\": num_ratings, \"Price\": prices, \"Expected Delivery\":expected_delivery, \"Availability\":availabilities,\"Returns/Exchange\": returns, \"Other Details\": other_details})\n",
    "    if save_as_csv:\n",
    "        df.to_csv(product+\"_details.csv\", sep=',')\n",
    "        print(f\"Save the data as a csv file {product}_details.csv\")\n",
    "    return d, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 1-48 of over 1,000 results for \"guitar\"\n",
      "Save the data as a csv file guitar_details.csv\n"
     ]
    }
   ],
   "source": [
    "#pd.DataFrame({'Brand Name':brands, \"Name of the Product\": product_names, \"Rating\":ratings, \"No. of Ratings\": num_ratings, \"Price\": prices, \"Expected Delivery\":expected_delivery, \"Availability\":availabilities})\n",
    "d, data = fetch_product_details_amazon('guitar',3,True)\n",
    "d.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Name of the Product</th>\n",
       "      <th>Rating</th>\n",
       "      <th>No. of Ratings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Returns/Exchange</th>\n",
       "      <th>Other Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visit the Kadence Store</td>\n",
       "      <td>Kadence Frontier Jumbo Semi Acoustic Guitar Wi...</td>\n",
       "      <td></td>\n",
       "      <td>379 ratings</td>\n",
       "      <td>₹ 5,999.00</td>\n",
       "      <td>FREE delivery: Saturday, April 24 Details\\nFas...</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>QUALITY STRINGS ---The surface is coated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brand: Medellin</td>\n",
       "      <td>Medellin MED-BLU-C Linden Wood Acoustic Guitar</td>\n",
       "      <td></td>\n",
       "      <td>341 ratings</td>\n",
       "      <td>₹ 2,399.00</td>\n",
       "      <td>FREE delivery: Friday, April 23 Details\\nFaste...</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Material: Wood\\nColour: Blue\\nAcoustic Guitar\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Visit the Kadence Store</td>\n",
       "      <td>Kadence Slowhand Premium Jumbo Semi Acoustic G...</td>\n",
       "      <td></td>\n",
       "      <td>100 ratings</td>\n",
       "      <td>₹ 10,999.00</td>\n",
       "      <td>FREE delivery: Saturday, April 24 Details</td>\n",
       "      <td>Only 1 left in stock.</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>QUALITY STRINGS ---The surface is coated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Visit the JUAREZ Store</td>\n",
       "      <td>Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...</td>\n",
       "      <td></td>\n",
       "      <td>8,818 ratings</td>\n",
       "      <td>₹ 2,499.00</td>\n",
       "      <td>FREE delivery: Saturday, April 24 Details</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>About this item\\nBlack Glossy Finish, Number o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Visit the JUAREZ Store</td>\n",
       "      <td>Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...</td>\n",
       "      <td></td>\n",
       "      <td>8,818 ratings</td>\n",
       "      <td>₹ 2,499.00</td>\n",
       "      <td>FREE delivery: Saturday, April 24 Details</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>About this item\\nBlack Glossy Finish, Number o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Brand: Shreearya Fashion</td>\n",
       "      <td>Shreearya Guitar 4-String Acoustic Guitar Musi...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Available from these sellers.</td>\n",
       "      <td>7 Days Returnable</td>\n",
       "      <td>Very Crisp and Clear Sound of Strings\\n4 Strin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Visit the JUAREZ Store</td>\n",
       "      <td>JUAREZ Fiésta 41 Inch Acoustic Guitar with Dua...</td>\n",
       "      <td></td>\n",
       "      <td>16 ratings</td>\n",
       "      <td>₹ 4,009.00</td>\n",
       "      <td>FREE delivery: Saturday, April 24 Details</td>\n",
       "      <td>Only 2 left in stock.</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>About this item\\nGlossy finish, Number of fret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Brand: Logicmart</td>\n",
       "      <td>Logicmart Guitar 4-String Acoustic Guitar Musi...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>₹ 799.00</td>\n",
       "      <td>FREE delivery: Monday, April 26 Details</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>7 Days Returnable</td>\n",
       "      <td>About this item\\nThe Guitar is made of very go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Brand: Fender</td>\n",
       "      <td>Fender CD 60 Dread V3 DS 6 String Acoustic Gui...</td>\n",
       "      <td></td>\n",
       "      <td>193 ratings</td>\n",
       "      <td>₹ 11,040.00</td>\n",
       "      <td>FREE delivery: Saturday, April 24 Details</td>\n",
       "      <td>Only 2 left in stock.</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Dreadnought body style spruce top with scallop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand Name  \\\n",
       "0    Visit the Kadence Store   \n",
       "1            Brand: Medellin   \n",
       "2    Visit the Kadence Store   \n",
       "3     Visit the JUAREZ Store   \n",
       "4     Visit the JUAREZ Store   \n",
       "..                       ...   \n",
       "76  Brand: Shreearya Fashion   \n",
       "77    Visit the JUAREZ Store   \n",
       "78          Brand: Logicmart   \n",
       "79             Brand: Fender   \n",
       "80                         -   \n",
       "\n",
       "                                  Name of the Product Rating No. of Ratings  \\\n",
       "0   Kadence Frontier Jumbo Semi Acoustic Guitar Wi...           379 ratings   \n",
       "1      Medellin MED-BLU-C Linden Wood Acoustic Guitar           341 ratings   \n",
       "2   Kadence Slowhand Premium Jumbo Semi Acoustic G...           100 ratings   \n",
       "3   Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...         8,818 ratings   \n",
       "4   Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...         8,818 ratings   \n",
       "..                                                ...    ...            ...   \n",
       "76  Shreearya Guitar 4-String Acoustic Guitar Musi...      -              -   \n",
       "77  JUAREZ Fiésta 41 Inch Acoustic Guitar with Dua...            16 ratings   \n",
       "78  Logicmart Guitar 4-String Acoustic Guitar Musi...      -              -   \n",
       "79  Fender CD 60 Dread V3 DS 6 String Acoustic Gui...           193 ratings   \n",
       "80                                                  -      -              -   \n",
       "\n",
       "          Price                                  Expected Delivery  \\\n",
       "0    ₹ 5,999.00  FREE delivery: Saturday, April 24 Details\\nFas...   \n",
       "1    ₹ 2,399.00  FREE delivery: Friday, April 23 Details\\nFaste...   \n",
       "2   ₹ 10,999.00          FREE delivery: Saturday, April 24 Details   \n",
       "3    ₹ 2,499.00          FREE delivery: Saturday, April 24 Details   \n",
       "4    ₹ 2,499.00          FREE delivery: Saturday, April 24 Details   \n",
       "..          ...                                                ...   \n",
       "76            -                                                  -   \n",
       "77   ₹ 4,009.00          FREE delivery: Saturday, April 24 Details   \n",
       "78     ₹ 799.00            FREE delivery: Monday, April 26 Details   \n",
       "79  ₹ 11,040.00          FREE delivery: Saturday, April 24 Details   \n",
       "80            -                                                  -   \n",
       "\n",
       "                     Availability    Returns/Exchange  \\\n",
       "0                       In stock.  7 Days Replacement   \n",
       "1                       In stock.  7 Days Replacement   \n",
       "2           Only 1 left in stock.  7 Days Replacement   \n",
       "3                       In stock.  7 Days Replacement   \n",
       "4                       In stock.  7 Days Replacement   \n",
       "..                            ...                 ...   \n",
       "76  Available from these sellers.   7 Days Returnable   \n",
       "77          Only 2 left in stock.  7 Days Replacement   \n",
       "78                      In stock.   7 Days Returnable   \n",
       "79          Only 2 left in stock.  7 Days Replacement   \n",
       "80                              -                   -   \n",
       "\n",
       "                                        Other Details  \n",
       "0   QUALITY STRINGS ---The surface is coated with ...  \n",
       "1   Material: Wood\\nColour: Blue\\nAcoustic Guitar\\...  \n",
       "2   QUALITY STRINGS ---The surface is coated with ...  \n",
       "3   About this item\\nBlack Glossy Finish, Number o...  \n",
       "4   About this item\\nBlack Glossy Finish, Number o...  \n",
       "..                                                ...  \n",
       "76  Very Crisp and Clear Sound of Strings\\n4 Strin...  \n",
       "77  About this item\\nGlossy finish, Number of fret...  \n",
       "78  About this item\\nThe Guitar is made of very go...  \n",
       "79  Dreadnought body style spruce top with scallop...  \n",
       "80                                                  -  \n",
       "\n",
       "[81 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a python program to access the search bar and search button on images.google.com and scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(folder_name, file_name, img_urls):\n",
    "    img_urls = img_urls\n",
    "    DIR = folder_name\n",
    "    \n",
    "    if not os.path.exists(DIR):\n",
    "                os.mkdir(DIR)\n",
    "    DIR = os.path.join(DIR, file_name)\n",
    "\n",
    "    if not os.path.exists(DIR):\n",
    "                os.mkdir(DIR)\n",
    "\n",
    "    elif os.path.exists(DIR):\n",
    "        folder = DIR\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "    ###downloading images\n",
    "    for i ,img in enumerate(img_urls):\n",
    "        try:        \n",
    "            r = requests.get(img, stream = True, timeout = 60)\n",
    "            \n",
    "            # Check if the image was retrieved successfully\n",
    "            if r.status_code == 200:\n",
    "                # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "                r.raw.decode_content = True\n",
    "    \n",
    "                # Open a local file with wb ( write binary ) permission.\n",
    "                with open(DIR+'\\\\'+file_name+'_'+str(i)+'.jpg','wb') as f:\n",
    "                    shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "                print(f'Image sucessfully Downloaded: {DIR}\\\\{file_name}_{str(i)}.jpg')\n",
    "            else:\n",
    "                print(\"Image Could not be retreived\")\n",
    "        except Exception as e:\n",
    "            print(\"Image Could not be retreived: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_google_images(search_keywords = [], num_images = 10):\n",
    "    for search_key in search_keywords:\n",
    "        d = get_drive_launch(\"https://images.google.com/\")\n",
    "        img_urls = []\n",
    "\n",
    "        d.find_element_by_xpath(\"//input[@title='Search']\").send_keys(search_key)\n",
    "        d.find_element_by_xpath(\"//button[@type='submit']\").click()\n",
    "\n",
    "        while len(img_urls) < num_images:\n",
    "            for i in range(5):\n",
    "                d.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "                time.sleep(2)\n",
    "            img_elmns = d.find_elements_by_xpath(\"//div[@class='isv-r PNCib MSM1fd BUooTd']\")\n",
    "            \n",
    "            time.sleep(1)\n",
    "            for img_elmn in img_elmns:\n",
    "                img_elmn.click()\n",
    "                time.sleep(5)\n",
    "                try:\n",
    "                    img_url = d.find_element_by_xpath(\"//a[@rlhc='1']/img[@class='n3VNCb']\").get_attribute('src')\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "                if 'http' in img_url and 'jpg' in img_url:\n",
    "                    img_urls.append(d.find_element_by_xpath(\"//a[@rlhc='1']/img[@class='n3VNCb']\").get_attribute('src'))\n",
    "                if len(img_urls) >= num_images:\n",
    "                    break\n",
    "        print(f\"Downloading {search_key} images\")\n",
    "        download_images(\"images\", search_key, img_urls)\n",
    "        img_urls.clear()\n",
    "        d.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fruits images\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_0.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_1.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_2.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_3.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_4.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_6.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_7.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_8.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_9.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_10.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_11.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_12.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_13.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_14.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_15.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_16.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_17.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_18.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_19.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_20.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_21.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_23.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_24.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_25.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_26.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_27.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_28.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_29.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_31.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_32.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_33.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_34.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_35.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_36.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_37.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_38.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_39.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_40.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_41.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_42.jpg\n",
      "Image Could not be retreived\n",
      "Image Could not be retreived:  HTTPSConnectionPool(host='www.savinodelbene.com', port=443): Max retries exceeded with url: /wp-content/uploads/2020/11/trasporto_logistica_freshfruits_vegetables.jpg (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1076)')))\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_45.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_46.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_47.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_48.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_49.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_51.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_52.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_53.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_54.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_55.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_56.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_57.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_58.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_59.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_60.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_61.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_62.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_63.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_64.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_65.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_66.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_67.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_68.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_69.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_70.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_71.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_72.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_73.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_74.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_75.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_76.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_77.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_78.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_79.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_80.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_81.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_82.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_83.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_84.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_85.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_86.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_87.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_88.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_89.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_90.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_91.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_92.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_93.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_94.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_95.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_96.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_97.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_98.jpg\n",
      "Image sucessfully Downloaded: images\\fruits\\fruits_99.jpg\n",
      "Downloading cars images\n",
      "Image sucessfully Downloaded: images\\cars\\cars_0.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_1.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_2.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_3.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_4.jpg\n",
      "Image Could not be retreived:  HTTPSConnectionPool(host='cars.usnews.com', port=443): Read timed out. (read timeout=60)\n",
      "Image sucessfully Downloaded: images\\cars\\cars_6.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_7.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_8.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_9.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_10.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_11.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_12.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_13.jpg\n",
      "Image Could not be retreived:  HTTPSConnectionPool(host='cars.usnews.com', port=443): Read timed out. (read timeout=60)\n",
      "Image sucessfully Downloaded: images\\cars\\cars_15.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_16.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_17.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_18.jpg\n",
      "Image Could not be retreived:  HTTPSConnectionPool(host='cars.usnews.com', port=443): Read timed out. (read timeout=60)\n",
      "Image sucessfully Downloaded: images\\cars\\cars_20.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_21.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_22.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_23.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_24.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_25.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_26.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_27.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_28.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_29.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_30.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_31.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\cars\\cars_33.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_34.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_35.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_36.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_37.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sucessfully Downloaded: images\\cars\\cars_38.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_39.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_40.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_41.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_42.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_43.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_44.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_45.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_46.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\cars\\cars_48.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_49.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_50.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_51.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_52.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_53.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_54.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_55.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_56.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_57.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_58.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_59.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_60.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_61.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_62.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_63.jpg\n",
      "Image Could not be retreived:  HTTPSConnectionPool(host='cars.usnews.com', port=443): Read timed out. (read timeout=60)\n",
      "Image sucessfully Downloaded: images\\cars\\cars_65.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_66.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_67.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_68.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_69.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_70.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\cars\\cars_72.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_73.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_74.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_75.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_76.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_77.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_78.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_79.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_80.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_81.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_82.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_83.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_84.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_85.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_86.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_87.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_88.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_89.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_90.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_91.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_92.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_93.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_94.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_95.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_96.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_97.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_98.jpg\n",
      "Image sucessfully Downloaded: images\\cars\\cars_99.jpg\n",
      "Downloading Machine Learning images\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_0.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_1.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_2.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_3.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_4.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_5.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_6.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_7.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_8.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_9.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_10.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_11.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_12.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_13.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_14.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_15.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_16.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_17.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_18.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_20.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_21.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_22.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_23.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_24.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_25.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_26.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_27.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_28.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_29.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_30.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_31.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_32.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_33.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_34.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_35.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_36.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_37.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_38.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_39.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_40.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_42.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_43.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_44.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_45.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_46.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_47.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_48.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_49.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_50.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_51.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_52.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_53.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_54.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_55.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_56.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_57.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_58.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_59.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_60.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_61.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_62.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_63.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_64.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_65.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_66.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_67.jpg\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_69.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_70.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_71.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_72.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_73.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_74.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_75.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_76.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_77.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_78.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_79.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_80.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_81.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_82.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_83.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_84.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_85.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_86.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_87.jpg\n",
      "Image Could not be retreived\n",
      "Image Could not be retreived\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_90.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_91.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_92.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_93.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_94.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_95.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_96.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_97.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_98.jpg\n",
      "Image sucessfully Downloaded: images\\Machine Learning\\Machine Learning_99.jpg\n"
     ]
    }
   ],
   "source": [
    "search_keys = ['fruits','cars','Machine Learning']\n",
    "download_google_images(search_keys,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_lat_gmap_for(city):\n",
    "    dr = get_drive_launch(\"https://www.google.com/maps\")\n",
    "\n",
    "    dr.find_element_by_id(\"searchboxinput\").send_keys(city)\n",
    "    dr.find_element_by_id(\"searchbox-searchbutton\").click()\n",
    "    try:\n",
    "        element = WebDriverWait(dr, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//button[@data-value='Directions']\"))\n",
    "        )\n",
    "    finally: \n",
    "        cur_url = dr.current_url\n",
    "\n",
    "    cur_url = cur_url.split('@')[1].split(',')\n",
    "    dr.quit()\n",
    "    return \"Longitude: \"+cur_url[0],\"Latitude: \"+cur_url[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longitude_latitude_for(city):\n",
    "    url = f'https://nominatim.openstreetmap.org/search/{city}?format=json'\n",
    "    response = requests.get(url).json()\n",
    "    return \"Longitude: \"+response[0][\"lat\"], \"Latitude: \"+response[0][\"lon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Longitude: 40.6971494', 'Latitude: -74.2598684')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_long_lat_gmap_for('new york')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Longitude: 40.7127281', 'Latitude: -74.0060152')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_longitude_latitude_for('new york')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Write a program to scrap details of all the funding deals for Third quarter (i.e. July 20 - September 20) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_trak(quarter, year):\n",
    "    url = \"https://trak.in/\"\n",
    "    q = quarter\n",
    "    year = str(year)\n",
    "    months = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "    dates = []\n",
    "    start_ups = []\n",
    "    verticals = []\n",
    "    sub_verticals =[]\n",
    "    cities = []\n",
    "    investors = [] \n",
    "    invest_types = []\n",
    "    amts = []\n",
    "\n",
    "    print(f\"Looking for Quarter {q} details in {year}...\")\n",
    "\n",
    "    if q==1:\n",
    "        months_window = months[0:3]\n",
    "    elif q==2:\n",
    "        months_window = months[3:6]\n",
    "    elif q==3:\n",
    "        months_window = months[6:9]\n",
    "    elif q==4:\n",
    "        months_window = months[9:]\n",
    "\n",
    "\n",
    "\n",
    "    d = get_drive_launch(url)\n",
    "    d.find_element_by_xpath(\"//div[@class='container']//a[contains(text(),'Funding Deals')]\").click()\n",
    "    time.sleep(3)\n",
    "    for month in months_window:\n",
    "        month = month+\", \"+year\n",
    "\n",
    "        print(f'Scrapping details for the month {month}...')\n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                date_elemns = d.find_elements_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//div[@class='dataTables_scrollBody']//td[@class='column-2']\")\n",
    "                if len(date_elemns) < 1:\n",
    "                    print(f'Details for {month} not found!')\n",
    "                    break                 \n",
    "                start_up_elemns = d.find_elements_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//div[@class='dataTables_scrollBody']//td[@class='column-3']\")\n",
    "                vertical_elemns = d.find_elements_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//div[@class='dataTables_scrollBody']//td[@class='column-4']\")\n",
    "                sub_vertical_elemns = d.find_elements_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//div[@class='dataTables_scrollBody']//td[@class='column-5']\")\n",
    "                city_elemns = d.find_elements_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//div[@class='dataTables_scrollBody']//td[@class='column-6']\")\n",
    "                investors_elemns = d.find_elements_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//div[@class='dataTables_scrollBody']//td[@class='column-7']\")\n",
    "                invest_type_elemns = d.find_elements_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//div[@class='dataTables_scrollBody']//td[@class='column-8']\")\n",
    "                amt_elemns = d.find_elements_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//div[@class='dataTables_scrollBody']//td[@class='column-9']/strong\")\n",
    "            except NoSuchElementException:\n",
    "                print(f'Details for {month} not found!')\n",
    "                break\n",
    "\n",
    "            for date_elemn,start_up_elemn,vertical_elemn,sub_vertical_elemn,city_elemn,investors_elemn,invest_type_elemn,amt_elemn in zip(date_elemns,start_up_elemns,vertical_elemns,sub_vertical_elemns,city_elemns,investors_elemns,invest_type_elemns,amt_elemns):\n",
    "                dates.append(date_elemn.text)\n",
    "                start_ups.append(start_up_elemn.text)\n",
    "                verticals.append(vertical_elemn.text)\n",
    "                sub_verticals.append(sub_vertical_elemn.text)\n",
    "                cities.append(city_elemn.text)\n",
    "                investors.append(investors_elemn.text)\n",
    "                invest_types.append(invest_type_elemn.text)\n",
    "                amts.append(amt_elemn.text)\n",
    "\n",
    "            try:\n",
    "                d.find_element_by_xpath(\"//h2[contains(text(),'\"+month+\"')]/following-sibling::div[1]//a[@class='paginate_button next']\").click()\n",
    "                time.sleep(2)\n",
    "            except (NoSuchElementException,ElementClickInterceptedException):\n",
    "                break\n",
    "    return d, pd.DataFrame({'Date':dates, \"Startup Name\": start_ups, \"Industry/Vertical\":verticals, \"Sub-Vertical\":sub_verticals, \"City/Location\":cities, \"Investors' Name\":investors, \"Investment type\":invest_types, \"Amount(In USD)\":amts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for Quarter 3 details in 2020...\n",
      "Scrapping details for the month July, 2020...\n",
      "Scrapping details for the month August, 2020...\n",
      "Scrapping details for the month September, 2020...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry/Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>City/Location</th>\n",
       "      <th>Investors' Name</th>\n",
       "      <th>Investment type</th>\n",
       "      <th>Amount(In USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Walmart Inc</td>\n",
       "      <td>M&amp;A</td>\n",
       "      <td>1,200,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Vedantu</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Coatue Management</td>\n",
       "      <td>Series D</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Crio</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Learning Platform for Developers</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>021 Capital</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>934,160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>goDutch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Group Payments</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Matrix India,Y Combinator, Global Founders Cap...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Mystifly</td>\n",
       "      <td>Airfare Marketplace</td>\n",
       "      <td>Ticketing, Airline Retailing, and Post-Ticketi...</td>\n",
       "      <td>Singapore and Bangalore</td>\n",
       "      <td>Recruit Co. Ltd.</td>\n",
       "      <td>pre-Series B</td>\n",
       "      <td>3,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>JetSynthesys</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Adar Poonawalla and Kris Gopalakrishnan.</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10/07/2020</td>\n",
       "      <td>gigIndia</td>\n",
       "      <td>Marketplace</td>\n",
       "      <td>Crowd Sourcing, Freelance</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Incubate Fund India and Beyond Next Ventures</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>974,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>PumPumPum</td>\n",
       "      <td>Automotive Rental</td>\n",
       "      <td>Used Car-leasing platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Early Adapters Syndicate</td>\n",
       "      <td>Seed</td>\n",
       "      <td>292,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>FLYX</td>\n",
       "      <td>OTT Player</td>\n",
       "      <td>Streaming Social Network</td>\n",
       "      <td>New York and Delhi</td>\n",
       "      <td>Raj Mishra, founder of AIT Global Inc</td>\n",
       "      <td>pre-Seed</td>\n",
       "      <td>200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Open Appliances Pvt. Ltd.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Internet-of-Things Security Solutions</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Unicorn India Ventures</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15/08/2020</td>\n",
       "      <td>Practo</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>Health care and Wellness</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>A1A Company</td>\n",
       "      <td>Series F</td>\n",
       "      <td>32,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Medlife</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Prasid Uno Family Trust and SC Credit Fund</td>\n",
       "      <td></td>\n",
       "      <td>23,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>HungerBox</td>\n",
       "      <td>FoodTech</td>\n",
       "      <td>Online Food Delivery Service</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>One97, Sabre Partners Trust, Pratithi Investme...</td>\n",
       "      <td>Series D1</td>\n",
       "      <td>1,560,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>Hyper-local Logistics</td>\n",
       "      <td>Online Delivery Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Existing Backers</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>Terra.do</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Climate School, E-learning</td>\n",
       "      <td>Stanford, California,</td>\n",
       "      <td>Stanford Angels and Entrepreneurs (India), BEE...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12/08/2020</td>\n",
       "      <td>Classplus</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>E-learning, Online Tutoring</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Falcon Edge</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>upto 15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14/08/2020</td>\n",
       "      <td>Niyo</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Niyo Solutions Inc.</td>\n",
       "      <td></td>\n",
       "      <td>6,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10/08/2020</td>\n",
       "      <td>ZestMoney</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Primrose Hills Ventures</td>\n",
       "      <td></td>\n",
       "      <td>10,670,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>07/08/2020</td>\n",
       "      <td>FreshToHome</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Food Delivery</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Ascent Capital</td>\n",
       "      <td>Venture</td>\n",
       "      <td>16,200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Eduvanz</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sequoia India, Unitus</td>\n",
       "      <td>Series A</td>\n",
       "      <td>5,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>03/08/2020</td>\n",
       "      <td>CrowdPouch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Elina Investments Pvt. Ltd</td>\n",
       "      <td>Angel</td>\n",
       "      <td>2,880,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Byju’s</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Silver Lake, Tiger Global, General Atlantic an...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>500,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>mCaffeine</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Skincare &amp; Haircare</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Amicus Capital Private Equity I LLP, Amicus Ca...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Qshala</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Curiosity Platform for Kids</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Rainmatter Capital</td>\n",
       "      <td>Angel</td>\n",
       "      <td>370,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>Winzo</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kalaari Capital Partners, IndigoEdge Managemen...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>15,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Hippo Video</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Newark, Delaware, United States of Amercia</td>\n",
       "      <td>Alpha Wave Incubation, Exfinity Venture Partne...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>Melorra</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Jewelry Store</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Shadow Holdings, Lightbox.</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>upto 8,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>1mg</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Gaja Capital, Tata Capital, Partners Group</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>mfine</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>On-Demand Healthcare Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Caretech Pte Inc</td>\n",
       "      <td>Series B</td>\n",
       "      <td>5,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>Apna</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Recruitment Platform</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Lightspeed India and Sequoia Capital India</td>\n",
       "      <td>Series A</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>03/09/2020</td>\n",
       "      <td>Railofy</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>WL &amp; RAC protection platform</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Chiratae Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>950,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date               Startup Name  \\\n",
       "0   15/07/2020                   Flipkart   \n",
       "1   16/07/2020                    Vedantu   \n",
       "2   16/07/2020                       Crio   \n",
       "3   14/07/2020                    goDutch   \n",
       "4   13/07/2020                   Mystifly   \n",
       "5   09/07/2020               JetSynthesys   \n",
       "6   10/07/2020                   gigIndia   \n",
       "7   15/07/2020                  PumPumPum   \n",
       "8   14/07/2020                       FLYX   \n",
       "9   13/07/2020  Open Appliances Pvt. Ltd.   \n",
       "10  15/08/2020                     Practo   \n",
       "11  13/08/2020                    Medlife   \n",
       "12  13/08/2020                  HungerBox   \n",
       "13  04/08/2020                      Dunzo   \n",
       "14  11/08/2020                   Terra.do   \n",
       "15  12/08/2020                  Classplus   \n",
       "16  14/08/2020                       Niyo   \n",
       "17  10/08/2020                  ZestMoney   \n",
       "18  07/08/2020                FreshToHome   \n",
       "19  13/08/2020                    Eduvanz   \n",
       "20  03/08/2020                 CrowdPouch   \n",
       "21  08/09/2020                     Byju’s   \n",
       "22  12/09/2020                  mCaffeine   \n",
       "23  09/09/2020                     Qshala   \n",
       "24  02/09/2020                      Winzo   \n",
       "25  09/09/2020                Hippo Video   \n",
       "26  07/09/2020                    Melorra   \n",
       "27  07/09/2020                        1mg   \n",
       "28  31/08/2020                      mfine   \n",
       "29  31/08/2020                       Apna   \n",
       "30  03/09/2020                    Railofy   \n",
       "\n",
       "                         Industry/Vertical  \\\n",
       "0                               E-commerce   \n",
       "1                                  EduTech   \n",
       "2                                  EduTech   \n",
       "3                                  FinTech   \n",
       "4                      Airfare Marketplace   \n",
       "5                 Gaming and Entertainment   \n",
       "6                              Marketplace   \n",
       "7                        Automotive Rental   \n",
       "8                               OTT Player   \n",
       "9                   Information Technology   \n",
       "10                              HealthTech   \n",
       "11                              E-commerce   \n",
       "12                                FoodTech   \n",
       "13                   Hyper-local Logistics   \n",
       "14                                 EduTech   \n",
       "15                                 EduTech   \n",
       "16                                 FinTech   \n",
       "17                                 FinTech   \n",
       "18                              E-commerce   \n",
       "19                                 FinTech   \n",
       "20                                 FinTech   \n",
       "21                                 EduTech   \n",
       "22                           Personal Care   \n",
       "23                                 EduTech   \n",
       "24                           Online Gaming   \n",
       "25  Video Customer Experience(CX) Platform   \n",
       "26                              E-commerce   \n",
       "27                              E-commerce   \n",
       "28                              HealthTech   \n",
       "29                         Human Resources   \n",
       "30                          Transportation   \n",
       "\n",
       "                                         Sub-Vertical  \\\n",
       "0                                          E-commerce   \n",
       "1                                     Online Tutoring   \n",
       "2                    Learning Platform for Developers   \n",
       "3                                      Group Payments   \n",
       "4   Ticketing, Airline Retailing, and Post-Ticketi...   \n",
       "5                            Gaming and Entertainment   \n",
       "6                           Crowd Sourcing, Freelance   \n",
       "7                           Used Car-leasing platform   \n",
       "8                            Streaming Social Network   \n",
       "9               Internet-of-Things Security Solutions   \n",
       "10                           Health care and Wellness   \n",
       "11                                    Online Pharmacy   \n",
       "12                       Online Food Delivery Service   \n",
       "13                           Online Delivery Services   \n",
       "14                  Online Climate School, E-learning   \n",
       "15                        E-learning, Online Tutoring   \n",
       "16                                 Financial Services   \n",
       "17                                 Financial Services   \n",
       "18                                      Food Delivery   \n",
       "19                                 Financial Services   \n",
       "20                                 Financial Services   \n",
       "21                                    Online Tutoring   \n",
       "22                                Skincare & Haircare   \n",
       "23                 Online Curiosity Platform for Kids   \n",
       "24                                      Online Gaming   \n",
       "25             Video Customer Experience(CX) Platform   \n",
       "26                               Online Jewelry Store   \n",
       "27                                    Online Pharmacy   \n",
       "28                      On-Demand Healthcare Services   \n",
       "29                               Recruitment Platform   \n",
       "30                       WL & RAC protection platform   \n",
       "\n",
       "                                 City/Location  \\\n",
       "0                                    Bangalore   \n",
       "1                                    Bangalore   \n",
       "2                                    Bangalore   \n",
       "3                                       Mumbai   \n",
       "4                      Singapore and Bangalore   \n",
       "5                                         Pune   \n",
       "6                                         Pune   \n",
       "7                                      Gurgaon   \n",
       "8                           New York and Delhi   \n",
       "9                                    Bangalore   \n",
       "10                                   Bangalore   \n",
       "11                                   Bangalore   \n",
       "12                                   Bangalore   \n",
       "13                                   Bangalore   \n",
       "14                       Stanford, California,   \n",
       "15                                       Noida   \n",
       "16                                   Bangalore   \n",
       "17                                   Bangalore   \n",
       "18                                   Bangalore   \n",
       "19                                      Mumbai   \n",
       "20                                   Bangalore   \n",
       "21                                   Bangalore   \n",
       "22                                      Mumbai   \n",
       "23                                   Bangalore   \n",
       "24                                   New Delhi   \n",
       "25  Newark, Delaware, United States of Amercia   \n",
       "26                                   Bangalore   \n",
       "27                                     Gurgaon   \n",
       "28                                   Bangalore   \n",
       "29                                   Bangalore   \n",
       "30                                      Mumbai   \n",
       "\n",
       "                                      Investors' Name         Investment type  \\\n",
       "0                                         Walmart Inc                     M&A   \n",
       "1                                   Coatue Management                Series D   \n",
       "2                                         021 Capital            pre-Series A   \n",
       "3   Matrix India,Y Combinator, Global Founders Cap...                    Seed   \n",
       "4                                    Recruit Co. Ltd.            pre-Series B   \n",
       "5            Adar Poonawalla and Kris Gopalakrishnan.  Venture-Series Unknown   \n",
       "6        Incubate Fund India and Beyond Next Ventures            pre-Series A   \n",
       "7                            Early Adapters Syndicate                    Seed   \n",
       "8               Raj Mishra, founder of AIT Global Inc                pre-Seed   \n",
       "9                              Unicorn India Ventures  Venture-Series Unknown   \n",
       "10                                        A1A Company                Series F   \n",
       "11         Prasid Uno Family Trust and SC Credit Fund                           \n",
       "12  One97, Sabre Partners Trust, Pratithi Investme...               Series D1   \n",
       "13                                   Existing Backers             In Progress   \n",
       "14  Stanford Angels and Entrepreneurs (India), BEE...                    Seed   \n",
       "15                                        Falcon Edge             In Progress   \n",
       "16                                Niyo Solutions Inc.                           \n",
       "17                            Primrose Hills Ventures                           \n",
       "18                                     Ascent Capital                 Venture   \n",
       "19                              Sequoia India, Unitus                Series A   \n",
       "20                         Elina Investments Pvt. Ltd                   Angel   \n",
       "21  Silver Lake, Tiger Global, General Atlantic an...          Private Equity   \n",
       "22  Amicus Capital Private Equity I LLP, Amicus Ca...                Series B   \n",
       "23                                 Rainmatter Capital                   Angel   \n",
       "24  Kalaari Capital Partners, IndigoEdge Managemen...                Series B   \n",
       "25  Alpha Wave Incubation, Exfinity Venture Partne...                Series A   \n",
       "26                         Shadow Holdings, Lightbox.          Debt Financing   \n",
       "27         Gaja Capital, Tata Capital, Partners Group             In Progress   \n",
       "28                                   Caretech Pte Inc                Series B   \n",
       "29         Lightspeed India and Sequoia Capital India                Series A   \n",
       "30                                  Chiratae Ventures                    Seed   \n",
       "\n",
       "     Amount(In USD)  \n",
       "0     1,200,000,000  \n",
       "1       100,000,000  \n",
       "2           934,160  \n",
       "3         1,700,000  \n",
       "4         3,300,000  \n",
       "5           400,000  \n",
       "6           974,200  \n",
       "7           292,800  \n",
       "8           200,000  \n",
       "9           500,000  \n",
       "10       32,000,000  \n",
       "11       23,000,000  \n",
       "12        1,560,000  \n",
       "13       30,000,000  \n",
       "14        1,400,000  \n",
       "15  upto 15,000,000  \n",
       "16        6,000,000  \n",
       "17       10,670,000  \n",
       "18       16,200,000  \n",
       "19        5,000,000  \n",
       "20        2,880,000  \n",
       "21      500,000,000  \n",
       "22        3,000,000  \n",
       "23          370,000  \n",
       "24       15,500,000  \n",
       "25        4,500,000  \n",
       "26   upto 8,900,000  \n",
       "27      100,000,000  \n",
       "28        5,400,000  \n",
       "29        8,000,000  \n",
       "30          950,000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, df = get_details_trak(3,2020)\n",
    "d.quit()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for Quarter 3 details in 2021...\n",
      "Scrapping details for the month July, 2021...\n",
      "Details for July, 2021 not found!\n",
      "Scrapping details for the month August, 2021...\n",
      "Details for August, 2021 not found!\n",
      "Scrapping details for the month September, 2021...\n",
      "Details for September, 2021 not found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry/Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>City/Location</th>\n",
       "      <th>Investors' Name</th>\n",
       "      <th>Investment type</th>\n",
       "      <th>Amount(In USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Startup Name, Industry/Vertical, Sub-Vertical, City/Location, Investors' Name, Investment type, Amount(In USD)]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, df = get_details_trak(3,2021)\n",
    "d.quit()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Write a program to scrap all the available details of top 10 gaming laptops from digit.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10(search_keyword):\n",
    "    url = \"https://www.digit.in/\"\n",
    "    products = []\n",
    "    descs = []\n",
    "    os = []\n",
    "    displays = []\n",
    "    processors = []\n",
    "    memories = []\n",
    "    weights = []\n",
    "    dimensions = []\n",
    "    graph_processors = []\n",
    "    stocks = []\n",
    "    prices = []\n",
    "\n",
    "    d = get_drive_launch(url)\n",
    "    time.sleep(3)\n",
    "    d.find_element_by_class_name(\"search\").click()\n",
    "    time.sleep(1)\n",
    "    d.find_element_by_id(\"globalPageSearchText\").send_keys(search_keyword)\n",
    "    time.sleep(2)\n",
    "    d.find_element_by_id(\"globalPageSearchText\").send_keys(Keys.RETURN)\n",
    "    time.sleep(2)\n",
    "    d.find_element_by_id(\"content_top10\").click()\n",
    "    search_results_elemn = d.find_element_by_class_name(\"searchPage\")\n",
    "    search_results_elemn.click()\n",
    "\n",
    "    for i in range(1,11):\n",
    "        products.append(d.find_element_by_xpath(\"//div[@data-index='\"+str(i)+\"']\").text)\n",
    "        data = d.find_element_by_xpath(\"//div[@data-index='\"+str(i)+\"']/following-sibling::div[@class='Section-center'][1]\").text.split('SPECIFICATION')\n",
    "        descs.append(data[0])\n",
    "        specs = data[1].split(\"\\n\")[1:]\n",
    "        os.append(specs[0].split(':')[1].strip())\n",
    "        displays.append(specs[1].split(':')[1].strip())\n",
    "        processors.append(specs[2].split(':')[1].strip())\n",
    "        memories.append(specs[3].split(':')[1].strip())\n",
    "        weights.append(specs[4].split(':')[1].strip())\n",
    "        dimensions.append(specs[5].split(':')[1].strip())\n",
    "        graph_processors.append(specs[6].split(':')[1].strip())\n",
    "        stocks.append(specs[7].split('₹')[0].strip().replace('Price :','NA'))\n",
    "        prices.append(specs[7].split('₹')[1].strip())\n",
    "\n",
    "    dataframe = pd.DataFrame({'Product Name':products, 'Description':descs, 'OS':os, 'Display':displays, 'Processor':processors, 'Memory':memories,\n",
    "                 'Weight':weights, 'Dimension':dimensions, 'Graphical Processors':graph_processors, 'Stock Availability':stocks\n",
    "                 , 'Price':prices})\n",
    "    return d, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>OS</th>\n",
       "      <th>Display</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Graphical Processors</th>\n",
       "      <th>Stock Availability</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.\\nMSI GT76 TITAN DT 9SG</td>\n",
       "      <td>Sporting a desktop graphics Intel Core i9-9900...</td>\n",
       "      <td>Windows 10 Pro</td>\n",
       "      <td>17.3\" (UHD 3840x2160)</td>\n",
       "      <td>Intel 9th Gen Core i9-9900K | 5000 MHz</td>\n",
       "      <td>1 TB HDD/64 GBGB DDR4</td>\n",
       "      <td>4.2 kg</td>\n",
       "      <td>397 x 330 x 33~42 mm</td>\n",
       "      <td>NVIDIA GeForce RTX 2080</td>\n",
       "      <td>NA</td>\n",
       "      <td>379990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.\\nALIENWARE 17 AREA-51M</td>\n",
       "      <td>The Alienware Area-51m was certainly the first...</td>\n",
       "      <td>Windows 10 Pro</td>\n",
       "      <td>17.3\" (FHD (1920 x 1080))</td>\n",
       "      <td>Intel 9th Gen Core i9-9900K | 5000 MHz</td>\n",
       "      <td>1 TB PCIe SSD/32GB DDR4</td>\n",
       "      <td>3.87 Kg</td>\n",
       "      <td>42 mm x 402.6 mm x 319.14 mm</td>\n",
       "      <td>NVIDIA GeForce RTX 2080</td>\n",
       "      <td>AVAILABLE</td>\n",
       "      <td>422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.\\nHP OMEN 15 2020</td>\n",
       "      <td>The new HP Omen 15 comes in both 10th generati...</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>15.6\" (1920 x 1080)</td>\n",
       "      <td>Intel i7-10750H 10th Gen | 1.6GHz</td>\n",
       "      <td>512 GB SSD/16 GBGB DDR4</td>\n",
       "      <td>5.40</td>\n",
       "      <td>14.09 x 9.44 x 0.89</td>\n",
       "      <td>Nvidia GeForce GTX 1650Ti</td>\n",
       "      <td>OUT OF STOCK</td>\n",
       "      <td>117790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.\\nASUS ZEPHYRUS G14</td>\n",
       "      <td>The Asus Zephyrus G14 is a first-of-its-kind g...</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>14\" (1920 x 1080)</td>\n",
       "      <td>AMD 3rd Generation Ryzen 9 | 3.3 GHz</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "      <td>1.65</td>\n",
       "      <td>32.5 x 22.1 x 1.8</td>\n",
       "      <td>NVIDIA GeForce RTX 2060</td>\n",
       "      <td>AVAILABLE</td>\n",
       "      <td>164990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.\\nLENOVO LEGION Y540</td>\n",
       "      <td>The Lenovo Legion Y540 is powered by an Intel ...</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>9th Generation Core Intel I7-9750H | 2.6 Ghz</td>\n",
       "      <td>1 TB SSD/8GB DDR4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>365mm x 260mm x 25.9mm</td>\n",
       "      <td>NVIDIA® GeForce RTX™ 2060</td>\n",
       "      <td>OUT OF STOCK</td>\n",
       "      <td>79990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.\\nASUS ROG ZEPHYRUS G GA502</td>\n",
       "      <td>The Ryzen 7 3750H powered Asus ROG Zephyrus G ...</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>15.6\" (1920 x 1080)</td>\n",
       "      <td>AMD Ryzen 7 Quad Core 3750H | 2.3 GHz</td>\n",
       "      <td>512 GB SSD/16GB DDR4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>360 x 252 x 20.4</td>\n",
       "      <td>NVIDIA Geforce GTX 1660 Ti</td>\n",
       "      <td>OUT OF STOCK</td>\n",
       "      <td>79990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.\\nASUS ROG ZEPHYRUS S GX531</td>\n",
       "      <td>The Asus Zephyrus S (GX531) manages to get a f...</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>9th Gen Intel Core i7-8750H | 2.2 GHz</td>\n",
       "      <td>512GB SSD/16 GBGB DDR4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>360 (W) x 268 (D) x 15.35~16.15 (H) mm</td>\n",
       "      <td>NVIDIA® GeForce RTX™ 2070 (Max-Q)</td>\n",
       "      <td>AVAILABLE</td>\n",
       "      <td>239990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.\\nMSI GT83VR 7RE TITAN SLI</td>\n",
       "      <td>MSI does not have a dual GTX 1080 gaming lapto...</td>\n",
       "      <td>Windows 10 Home 64 bit</td>\n",
       "      <td>18.4\" (1920 x 1080)</td>\n",
       "      <td>Intel CM238 Core i7-7820HK+CM238 7th Gen | 3.5GHz</td>\n",
       "      <td>1.5 TB SATA/64GB DDR4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>458 x 339 x 69</td>\n",
       "      <td>Dual GTX1070</td>\n",
       "      <td>NA</td>\n",
       "      <td>349990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.\\nASUS ROG ZEPHYRUS DUO 15</td>\n",
       "      <td>The machine is powered by an Intel Core i7-108...</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>15.6\" (3840 x 1100)</td>\n",
       "      <td>Intel Core i7 10th Gen 10875H | NA</td>\n",
       "      <td>512 GB SSD/4 GBGB DDR4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>268.30 x 360.00 x 20.90</td>\n",
       "      <td>NVIDIA GeForce RTX 2070 Max-Q</td>\n",
       "      <td>AVAILABLE</td>\n",
       "      <td>244990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.\\nDELL G3</td>\n",
       "      <td>The Dell G3 is a capable entry-level gaming la...</td>\n",
       "      <td>Windows 10 Home Plus</td>\n",
       "      <td>15.6 MP | NA</td>\n",
       "      <td>8th Gen Intel core i5-8300H | 2.3GHz</td>\n",
       "      <td>1TB HDD/8GB DDR4</td>\n",
       "      <td>2.53</td>\n",
       "      <td>22.7 X 380 X 258</td>\n",
       "      <td>NVidia GeForce GTX 1050</td>\n",
       "      <td>AVAILABLE</td>\n",
       "      <td>73900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Product Name  \\\n",
       "0      1.\\nMSI GT76 TITAN DT 9SG   \n",
       "1      2.\\nALIENWARE 17 AREA-51M   \n",
       "2            3.\\nHP OMEN 15 2020   \n",
       "3          4.\\nASUS ZEPHYRUS G14   \n",
       "4         5.\\nLENOVO LEGION Y540   \n",
       "5  6.\\nASUS ROG ZEPHYRUS G GA502   \n",
       "6  7.\\nASUS ROG ZEPHYRUS S GX531   \n",
       "7   8.\\nMSI GT83VR 7RE TITAN SLI   \n",
       "8   9.\\nASUS ROG ZEPHYRUS DUO 15   \n",
       "9                   10.\\nDELL G3   \n",
       "\n",
       "                                         Description                      OS  \\\n",
       "0  Sporting a desktop graphics Intel Core i9-9900...          Windows 10 Pro   \n",
       "1  The Alienware Area-51m was certainly the first...          Windows 10 Pro   \n",
       "2  The new HP Omen 15 comes in both 10th generati...         Windows 10 Home   \n",
       "3  The Asus Zephyrus G14 is a first-of-its-kind g...         Windows 10 Home   \n",
       "4  The Lenovo Legion Y540 is powered by an Intel ...         Windows 10 Home   \n",
       "5  The Ryzen 7 3750H powered Asus ROG Zephyrus G ...         Windows 10 Home   \n",
       "6  The Asus Zephyrus S (GX531) manages to get a f...         Windows 10 Home   \n",
       "7  MSI does not have a dual GTX 1080 gaming lapto...  Windows 10 Home 64 bit   \n",
       "8  The machine is powered by an Intel Core i7-108...              Windows 10   \n",
       "9  The Dell G3 is a capable entry-level gaming la...    Windows 10 Home Plus   \n",
       "\n",
       "                     Display  \\\n",
       "0      17.3\" (UHD 3840x2160)   \n",
       "1  17.3\" (FHD (1920 x 1080))   \n",
       "2        15.6\" (1920 x 1080)   \n",
       "3          14\" (1920 x 1080)   \n",
       "4        15.6\" (1920 X 1080)   \n",
       "5        15.6\" (1920 x 1080)   \n",
       "6        15.6\" (1920 X 1080)   \n",
       "7        18.4\" (1920 x 1080)   \n",
       "8        15.6\" (3840 x 1100)   \n",
       "9               15.6 MP | NA   \n",
       "\n",
       "                                           Processor                   Memory  \\\n",
       "0             Intel 9th Gen Core i9-9900K | 5000 MHz    1 TB HDD/64 GBGB DDR4   \n",
       "1             Intel 9th Gen Core i9-9900K | 5000 MHz  1 TB PCIe SSD/32GB DDR4   \n",
       "2                  Intel i7-10750H 10th Gen | 1.6GHz  512 GB SSD/16 GBGB DDR4   \n",
       "3               AMD 3rd Generation Ryzen 9 | 3.3 GHz    1 TB SSD/16 GBGB DDR4   \n",
       "4       9th Generation Core Intel I7-9750H | 2.6 Ghz        1 TB SSD/8GB DDR4   \n",
       "5              AMD Ryzen 7 Quad Core 3750H | 2.3 GHz     512 GB SSD/16GB DDR4   \n",
       "6              9th Gen Intel Core i7-8750H | 2.2 GHz   512GB SSD/16 GBGB DDR4   \n",
       "7  Intel CM238 Core i7-7820HK+CM238 7th Gen | 3.5GHz    1.5 TB SATA/64GB DDR4   \n",
       "8                 Intel Core i7 10th Gen 10875H | NA   512 GB SSD/4 GBGB DDR4   \n",
       "9               8th Gen Intel core i5-8300H | 2.3GHz         1TB HDD/8GB DDR4   \n",
       "\n",
       "    Weight                               Dimension  \\\n",
       "0   4.2 kg                    397 x 330 x 33~42 mm   \n",
       "1  3.87 Kg            42 mm x 402.6 mm x 319.14 mm   \n",
       "2     5.40                     14.09 x 9.44 x 0.89   \n",
       "3     1.65                       32.5 x 22.1 x 1.8   \n",
       "4      2.3                  365mm x 260mm x 25.9mm   \n",
       "5      2.2                        360 x 252 x 20.4   \n",
       "6      2.1  360 (W) x 268 (D) x 15.35~16.15 (H) mm   \n",
       "7      5.5                          458 x 339 x 69   \n",
       "8      2.4                 268.30 x 360.00 x 20.90   \n",
       "9     2.53                        22.7 X 380 X 258   \n",
       "\n",
       "                Graphical Processors Stock Availability   Price  \n",
       "0            NVIDIA GeForce RTX 2080                 NA  379990  \n",
       "1            NVIDIA GeForce RTX 2080          AVAILABLE  422000  \n",
       "2          Nvidia GeForce GTX 1650Ti       OUT OF STOCK  117790  \n",
       "3            NVIDIA GeForce RTX 2060          AVAILABLE  164990  \n",
       "4          NVIDIA® GeForce RTX™ 2060       OUT OF STOCK   79990  \n",
       "5         NVIDIA Geforce GTX 1660 Ti       OUT OF STOCK   79990  \n",
       "6  NVIDIA® GeForce RTX™ 2070 (Max-Q)          AVAILABLE  239990  \n",
       "7                       Dual GTX1070                 NA  349990  \n",
       "8      NVIDIA GeForce RTX 2070 Max-Q          AVAILABLE  244990  \n",
       "9            NVidia GeForce GTX 1050          AVAILABLE   73900  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,df = get_top_10(\"gaming laptops\")\n",
    "d.quit()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
